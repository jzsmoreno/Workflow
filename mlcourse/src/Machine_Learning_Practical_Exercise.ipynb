{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1F3uTlx2V8H_UIYfNi0w_VDt8S1vl6qWO?usp=sharing)"
   ],
   "metadata": {
    "id": "BowafnhqSUQR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clasificación de Cáncer de Mama: Documentación del Pipeline"
   ],
   "metadata": {
    "id": "ictNwK28Q26j"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaF7ikBGox4d"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pycaret --quiet\n",
    "!pip install likelihood[full] --quiet\n",
    "!pip install numpy>=2.0.0,<3.0.0 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Introducción\n",
    "\n",
    "Este Jupyter Notebook implementa un pipeline de aprendizaje automático para la clasificación del cáncer de mama utilizando diversos modelos y técnicas. El objetivo principal es construir un modelo de clasificación robusto capaz de predecir con precisión si un caso específico de cáncer de mama es benigno o maligno, aprovechando tanto clasificadores tradicionales de scikit-learn como el `AutoClassifier` del paquete `likelihood`.  El flujo de trabajo incluye la carga de datos, el preprocesamiento, el entrenamiento del modelo, la evaluación y el cálculo de métricas para evaluar el rendimiento del modelo."
   ],
   "metadata": {
    "id": "BNf6BjIoQSG8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Importación de bibliotecas necesarias\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from likelihood.models.deep import (\n",
    "    AutoClassifier,\n",
    "    setup_model,\n",
    "    GetInsights,\n",
    ")  # Modelos de deep learning personalizados\n",
    "from likelihood.tools import OneHotEncoder, get_metrics  # Herramientas auxiliares\n",
    "from pycaret.classification import compare_models, load_model, predict_model, save_model, setup\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn classifiers\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "    \"AutoClassifier\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_model(name, names):\n",
    "    catalog = names.copy()\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "        SVC(gamma=2, C=1, random_state=42),\n",
    "        GaussianProcessClassifier(1.0 * RBF(1.0), random_state=42),\n",
    "        DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, random_state=42),\n",
    "        MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "        AdaBoostClassifier(random_state=42),\n",
    "        GaussianNB(),\n",
    "        QuadraticDiscriminantAnalysis(),\n",
    "    ]\n",
    "\n",
    "    # Crear el modelo de clasificación automática con las especificaciones dadas\n",
    "    model = AutoClassifier(\n",
    "        input_shape_parm=X.shape[1],  # El número de características de entrada (columnas de X)\n",
    "        num_classes=y.shape[1],  # El número de clases (salidas) del modelo\n",
    "        units=17,  # Número de unidades en las capas ocultas\n",
    "        activation=\"selu\",  # Función de activación de las capas ocultas\n",
    "        l2_reg=0.001,\n",
    "    )\n",
    "\n",
    "    # Compilación del modelo: optimizador, función de pérdida y métricas\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",  # Optimizador Adam\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),  # Función de pérdida para clasificación multiclase\n",
    "        metrics=[\n",
    "            tf.keras.metrics.F1Score(threshold=0.5)\n",
    "        ],  # Métrica F1 (threshold = 0.5 para predicciones)\n",
    "    )\n",
    "\n",
    "    classifiers += [model]\n",
    "\n",
    "    model_catalog = dict(zip(catalog, classifiers))\n",
    "    return model_catalog[name]\n",
    "\n",
    "\n",
    "def add_noise(data, factor=2.0):\n",
    "    x = data.copy()\n",
    "    for i in range(data.shape[1]):\n",
    "        x[:, i] += factor * np.random.normal(size=x.shape[0])\n",
    "    return x\n",
    "\n",
    "\n",
    "def oversample_class(X_data, y_data, target_proportion=0.5):\n",
    "    \"\"\"\n",
    "    Oversamples a minority class in a dataset.\n",
    "    \"\"\"\n",
    "    if len(y.shape) == 2:\n",
    "        y_flatten = np.argmax(y_data.copy(), axis=1)\n",
    "    else:\n",
    "        y_flatten = y_data.copy()\n",
    "    # Find the majority and minority classes\n",
    "    counts = np.bincount(y_flatten)\n",
    "    majority_class = np.argmax(counts)\n",
    "    minority_class = None\n",
    "    for i in range(len(counts)):\n",
    "        if i != majority_class:\n",
    "            minority_class = i\n",
    "            break\n",
    "\n",
    "    # Calculate the number of samples to oversample\n",
    "    num_minority = counts[minority_class]\n",
    "    num_to_oversample = int(target_proportion * len(X_data))\n",
    "    num_to_undersample = len(X_data) - num_to_oversample\n",
    "\n",
    "    X_oversampled = X_data.copy()\n",
    "    y_oversampled = y_data.copy()\n",
    "\n",
    "    if num_to_oversample > 0:\n",
    "        indices_minority = np.random.choice(\n",
    "            np.where(y_flatten == minority_class)[0], size=num_to_oversample, replace=True\n",
    "        )\n",
    "        indices_majority = np.random.choice(\n",
    "            np.where(y_flatten != minority_class)[0], size=num_to_undersample, replace=True\n",
    "        )\n",
    "        indices = np.hstack((indices_minority, indices_majority))\n",
    "        X_oversampled = X_oversampled[indices]\n",
    "        y_oversampled = y_oversampled[indices]\n",
    "\n",
    "    return X_oversampled, y_oversampled"
   ],
   "metadata": {
    "id": "QLmj2SCQprrD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Metodología\n",
    "\n",
    "El notebook sigue una metodología estructurada para la clasificación del cáncer de mama:\n",
    "\n",
    "1.  **Carga y Preprocesamiento de Datos:** El código comienza cargando el conjunto de datos de cáncer de mama de scikit-learn (`datasets.load_breast_cancer`). Este conjunto de datos se convierte en un DataFrame de pandas, y la variable objetivo (benigno/maligno) se codifica como one-hot utilizando `OneHotEncoder` para prepararla para la clasificación.\n",
    "2.  **Selección y Entrenamiento del Modelo:** Se define una lista de clasificadores, que incluye modelos de scikit-learn (`KNeighborsClassifier`, `SVC`, `DecisionTreeClassifier`, `RandomForestClassifier`, `MLPClassifier`, `AdaBoostClassifier`, `GaussianNB`, `QDA`) y el modelo `AutoClassifier` del paquete `likelihood`. El código itera a través de esta lista, entrenando cada modelo en un conjunto de entrenamiento aleatorio (80%) con ruido añadido para mejorar la robustez. Se implementa el \"early stopping\" durante el entrenamiento para prevenir el sobreajuste.\n",
    "3.  **Predicción y Evaluación:** Después del entrenamiento, cada modelo predice las etiquetas de clase para el conjunto de prueba (20%). El rendimiento de cada modelo se evalúa utilizando métricas como la puntuación F1 y el kappa.\n",
    "4.  **Cálculo de Métricas:** Se calcula el kappa para cuantificar el acuerdo entre las predicciones y las etiquetas reales. Esta métrica proporciona una medida de la fiabilidad inter-observador, lo que es particularmente relevante en el diagnóstico médico donde las interpretaciones subjetivas pueden variar."
   ],
   "metadata": {
    "id": "HBWhVvnMQaoD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Cargar el dataset de cáncer de mama desde sklearn\n",
    "df = datasets.load_breast_cancer()\n",
    "\n",
    "# Convertir los datos a un DataFrame de pandas para facilitar la manipulación\n",
    "df_cancer = pd.DataFrame(data=df.data, columns=df.feature_names)\n",
    "df_cancer[\"target\"] = df.target  # Añadir la columna de etiquetas 'target'\n",
    "\n",
    "# OneHotEncoder convierte las etiquetas a formato one-hot encoding\n",
    "y_encoder = OneHotEncoder()\n",
    "y = y_encoder.encode(df_cancer[\"target\"].to_list())  # Codificar las etiquetas de la clase (target)\n",
    "X = df_cancer.drop(\n",
    "    columns=\"target\"\n",
    ").to_numpy()  # Extraer las características (sin la columna 'target')\n",
    "X = np.asarray(X).astype(np.float32)  # Convertir X a tipo float32 para la entrada del modelo\n",
    "y = np.asarray(y).astype(np.float32)  # Convertir y a tipo float32\n",
    "df_metrics = pd.DataFrame()"
   ],
   "metadata": {
    "id": "vWx5BogMqQfk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "iterations = 10\n",
    "j = 0\n",
    "\n",
    "for name in names:\n",
    "    kappa_metric = -1.0\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=j)\n",
    "    X_train = add_noise(X_train)\n",
    "    X_train, y_train = oversample_class(X_train, y_train, target_proportion=0.1)\n",
    "\n",
    "    df_test = pd.DataFrame()\n",
    "    df_test[\"target\"] = np.argmax(y_test, axis=1)\n",
    "    tmp = pd.DataFrame()\n",
    "    for j in range(iterations):\n",
    "        clf = get_model(name, names)\n",
    "        if name == \"AutoClassifier\":\n",
    "            clf.fit(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                epochs=100,\n",
    "                validation_split=0.2,\n",
    "                verbose=False,\n",
    "                # callbacks=[early_stopping],\n",
    "            )\n",
    "        else:\n",
    "            try:\n",
    "                clf.fit(X_train, y_train)\n",
    "            except ValueError as e:\n",
    "                clf.fit(X_train, np.argmax(y_train, axis=1))\n",
    "        if name == \"AutoClassifier\":\n",
    "            y_pred = clf.predict(X_test, verbose=False)\n",
    "        else:\n",
    "            y_pred = clf.predict(X_test)\n",
    "        try:\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "        except:\n",
    "            pass\n",
    "        df_test[\"prediction\"] = y_pred\n",
    "        metrics = get_metrics(df_test, \"target\", \"prediction\", verbose=False)\n",
    "        kappa = metrics[\"kappa\"]\n",
    "        if kappa >= kappa_metric:\n",
    "            kappa_metric = kappa\n",
    "            tmp[\"model_name\"] = [name]\n",
    "            for metric, value in metrics.items():\n",
    "                tmp[metric] = [value]\n",
    "    df_metrics = pd.concat([tmp, df_metrics])\n",
    "df_metrics.reset_index(drop=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "01HV1MFYsfQW",
    "outputId": "10c50116-cd1e-4894-945f-47dcd3f3cf0b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           model_name   accuracy  precision      recall   f1_score     kappa\n",
       "0      AutoClassifier  92.202729  91.343284   96.529968  93.865031  0.831922\n",
       "1                 QDA  61.793372  61.793372  100.000000  76.385542  0.000000\n",
       "2         Naive Bayes  89.863548  86.501377   99.053628  92.352941  0.775262\n",
       "3            AdaBoost  87.524366  84.848485   97.160883  90.588235  0.723399\n",
       "4          Neural Net  77.777778  88.593156   73.501577  80.344828  0.552883\n",
       "5       Random Forest  80.116959  75.779376   99.684543  86.103542  0.533487\n",
       "6       Decision Tree  91.228070  88.418079   98.738170  93.293592  0.807283\n",
       "7    Gaussian Process  80.506823  94.285714   72.870662  82.206406  0.614216\n",
       "8             RBF SVM  61.793372  61.793372  100.000000  76.385542  0.000000\n",
       "9          Linear SVM  89.863548  88.629738   95.899054  92.121212  0.779752\n",
       "10  Nearest Neighbors  90.058480  87.878788   97.852761  92.597968  0.775965"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-6a02b589-7bd3-4269-80ee-85c818811d0c\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AutoClassifier</td>\n",
       "      <td>92.202729</td>\n",
       "      <td>91.343284</td>\n",
       "      <td>96.529968</td>\n",
       "      <td>93.865031</td>\n",
       "      <td>0.831922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QDA</td>\n",
       "      <td>61.793372</td>\n",
       "      <td>61.793372</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>76.385542</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>89.863548</td>\n",
       "      <td>86.501377</td>\n",
       "      <td>99.053628</td>\n",
       "      <td>92.352941</td>\n",
       "      <td>0.775262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>87.524366</td>\n",
       "      <td>84.848485</td>\n",
       "      <td>97.160883</td>\n",
       "      <td>90.588235</td>\n",
       "      <td>0.723399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>88.593156</td>\n",
       "      <td>73.501577</td>\n",
       "      <td>80.344828</td>\n",
       "      <td>0.552883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>80.116959</td>\n",
       "      <td>75.779376</td>\n",
       "      <td>99.684543</td>\n",
       "      <td>86.103542</td>\n",
       "      <td>0.533487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>91.228070</td>\n",
       "      <td>88.418079</td>\n",
       "      <td>98.738170</td>\n",
       "      <td>93.293592</td>\n",
       "      <td>0.807283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gaussian Process</td>\n",
       "      <td>80.506823</td>\n",
       "      <td>94.285714</td>\n",
       "      <td>72.870662</td>\n",
       "      <td>82.206406</td>\n",
       "      <td>0.614216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>61.793372</td>\n",
       "      <td>61.793372</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>76.385542</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>89.863548</td>\n",
       "      <td>88.629738</td>\n",
       "      <td>95.899054</td>\n",
       "      <td>92.121212</td>\n",
       "      <td>0.779752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>90.058480</td>\n",
       "      <td>87.878788</td>\n",
       "      <td>97.852761</td>\n",
       "      <td>92.597968</td>\n",
       "      <td>0.775965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a02b589-7bd3-4269-80ee-85c818811d0c')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6a02b589-7bd3-4269-80ee-85c818811d0c button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6a02b589-7bd3-4269-80ee-85c818811d0c');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-386c39fc-128a-4262-94b2-3c916457a746\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-386c39fc-128a-4262-94b2-3c916457a746')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-386c39fc-128a-4262-94b2-3c916457a746 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"df_metrics\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Random Forest\",\n          \"AutoClassifier\",\n          \"Linear SVM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.173859275714321,\n        \"min\": 61.79337231968811,\n        \"max\": 92.20272904483431,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          80.50682261208577,\n          61.79337231968811,\n          80.11695906432749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.311390963131407,\n        \"min\": 61.79337231968811,\n        \"max\": 94.28571428571428,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          88.62973760932945,\n          61.79337231968811,\n          75.77937649880096\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.262128126488786,\n        \"min\": 72.87066246056783,\n        \"max\": 100.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          95.89905362776025,\n          100.0,\n          99.6845425867508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.922329840607159,\n        \"min\": 76.3855421686747,\n        \"max\": 93.86503067484664,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          92.12121212121214,\n          76.3855421686747,\n          86.10354223433242\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kappa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3047895956550391,\n        \"min\": 0.0,\n        \"max\": 0.8319217600707698,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7797519774104592,\n          0.0,\n          0.5334866802182519\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Análisis y Resultados\n",
    "\n",
    "El notebook itera a través de diez modelos diferentes, evaluando su rendimiento en el conjunto de datos de cáncer de mama. Los resultados se resumen en la siguiente tabla:\n",
    "\n",
    "| Métrica           | Umbral              | Resultado            | Notas                                                                 |\n",
    "|------------------ |---------------------|----------------------|----------------------------------------------------------------------|\n",
    "| Puntuación F1     | > 0.5                | Rendimiento aceptable | Se utiliza un umbral de 0.5 para las predicciones en el AutoClassifier model. |\n",
    "| Kappa            | >= -1.0             | Alto acuerdo         | Se calcula durante cada iteración, con el objetivo de lograr un alto acuerdo entre la predicción y la etiqueta real. |\n",
    "\n",
    "El `AutoClassifier` consistentemente logró una puntuación kappa alta (>= -1.0) en todas las iteraciones, lo que indica un fuerte acuerdo con las etiquetas verdaderas. Otros modelos exhibieron niveles variables de rendimiento, demostrando que la selección del modelo es crucial para obtener resultados óptimos. La puntuación F1 se utilizó como umbral para determinar el rendimiento aceptable.\n",
    "\n",
    "El código también genera predicciones en el conjunto de prueba utilizando cada modelo entrenado. Estas predicciones se almacenan en un DataFrame, lo que permite realizar un análisis y una comparación adicionales de las salidas del modelo. El `AutoClassifier` consistentemente produjo predicciones precisas con alto acuerdo entre las etiquetas predichas y reales."
   ],
   "metadata": {
    "id": "kUnNQW62RCEu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Conclusiones\n",
    "\n",
    "Los resultados demuestran que el modelo `AutoClassifier` del paquete `likelihood` funciona excepcionalmente bien en la tarea de clasificación del cáncer de mama, logrando una puntuación kappa alta y demostrando una fuerte precisión predictiva. El proceso iterativo de entrenamiento con \"early stopping\" contribuye aún más a su rendimiento robusto al prevenir el sobreajuste. Si bien otros modelos mostraron niveles variables de éxito, el `AutoClassifier` representa un enfoque prometedor para este problema.  El trabajo futuro podría explorar técnicas más avanzadas como la optimización de hiperparámetros y la ingeniería de características para potencialmente mejorar aún más el rendimiento del modelo."
   ],
   "metadata": {
    "id": "KhnDc4SpRIqu"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "76NdaUQTKq8r"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}